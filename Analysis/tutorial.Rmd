---
title: "Project 3: project3package Tutorial"
author: "Anika Lindley"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{project3package Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

The package `project3package` contains four functions. `my_t.test` and `my_lm` are used to make statistical inferences and `my_knn_cv` and `my_rf_cv` use cross validation to assess the predictive performance of models made using k-nearest neighbors and random forest, respectively.

## Instalation

To install `project3package` from GitGub, run the following code in your console:

```{r, eval = FALSE}
install.packages("devtools")
devtools::install_github("anikalindley/project3package", build_vignette = TRUE, build_opts = c())
```

```{r}
library(project3package)
```

# my_rf_cv

To demonstate the use of my_rf_cv I will predict the body mass of penguins using bill length, bill dpeth, and flipper length as covariates. 

```{r}

library(reshape2)
library(ggplot2)

source("../Code/my_rf_cv.R")

# matrix to store random forest cross-validation output
my_rf <- matrix(NA, 30, 3)

for (i in c(2, 5, 10)) {
  for(j in 1:30) {
    if (i == 2) {
       my_rf[j, 1] <- my_rf_cv(i)
    } else if (i == 5) {
       my_rf[j, 2] <- my_rf_cv(i)
    } else {
       my_rf[j, 3] <- my_rf_cv(i)
    }
  }
}

# store my_rf as data frame
my_df <- data.frame(my_rf)
# name columns
colnames(my_df) <- c("k = 2", "k = 5", "k = 10")
# assign variable names to each value
my_df <- melt(my_df, measure.vars = c("k = 2", "k = 5", "k = 10"))

# create a boxplot for each value of k
ggplot(data = my_df, aes(x = variable, y = value)) + 
  geom_boxplot() + 
  theme_bw(base_size = 12) + 
  labs(x = "Number of Folds", y = "Average MSE")

# create table to store CV MSE and SD
my_table <- matrix(NA, 3, 2)
my_df2 <- data.frame(my_rf)

# average CV MSE for each value of k
my_means <- colMeans(my_df2)
# standard deviation for each value of k
my_sd <- apply(my_df2, 2, sd)

# add average CV MSE to table
my_table[, 1] <- my_means
# add standard deviation to table
my_table[, 2] <- my_sd

# add column names
colnames(my_table) <- c("Avg MSE", "SD")
# add row names
row.names(my_table) <- c("k = 2", "k = 5", "k = 10")

my_table

```

As the number of folds increases, the average mean squared error of the predictions decreases and the standard deviation of the predictions decreases. This suggests that the 10-fold random forest cross validation model has the best predictive performance, as the average MSE and SD are lower than the 2- and 5- fold models. In general, as k increases there is a chance of overfitting becasue as k increases, more of the full data set is being used to make the predicitons and less is left to test the accuracy of the predictions. In this case, I belive that the 10-fold model leaves enough data left to accuratly assess the model and yields the best predictions compared to the other models. 
